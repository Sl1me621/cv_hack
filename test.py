import cv2
import numpy as np

def detect_stop_sign_simple(frame, debug=False):
    """
    –£–ø—Ä–æ—â–µ–Ω–Ω–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∑–Ω–∞–∫–∞ STOP:
    - –ü–æ –∫—Ä–∞—Å–Ω–æ–º—É —Ü–≤–µ—Ç—É –≤ HSV
    - –ü–æ —Ä–∞–∑–º–µ—Ä—É –∫–æ–Ω—Ç—É—Ä–∞
    - –ü–æ —Ñ–æ—Ä–º–µ (–º–Ω–æ–≥–æ—É–≥–æ–ª—å–Ω–∏–∫, –±–ª–∏–∑–∫–∏–π –∫ –≤–æ—Å—å–º–∏—É–≥–æ–ª—å–Ω–∏–∫—É)
    """

    # –ü–æ—Ä–æ–≥–∏ –∫—Ä–∞—Å–Ω–æ–≥–æ —Ü–≤–µ—Ç–∞ (–º–æ–∂–Ω–æ –ø–æ—Ç–æ–º –ø–æ–¥–∫—Ä—É—Ç–∏—Ç—å –ø–æ–¥ —Å–≤–æ–∏ –≤–∏–¥–µ–æ)
    lower_red1 = np.array([0, 100, 100])
    upper_red1 = np.array([10, 255, 255])
    lower_red2 = np.array([12, 127, 203])
    upper_red2 = np.array([179, 255, 238])

    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)

    # –ú–∞—Å–∫–∞ –∫—Ä–∞—Å–Ω–æ–≥–æ
    mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
    mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
    red_mask = mask2

    # –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—è –¥–ª—è –æ—á–∏—Å—Ç–∫–∏
    kernel = np.ones((5, 5), np.uint8)
    red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_OPEN, kernel)
    red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_CLOSE, kernel)

    contours, _ = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    h, w = frame.shape[:2]
    frame_area = h * w

    for contour in contours:
        area = cv2.contourArea(contour)
        if area < frame_area * 0.001 or area > frame_area * 0.3:
            continue  # —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–µ –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –æ–≥—Ä–æ–º–Ω—ã–µ

        # –ê–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—è –º–Ω–æ–≥–æ—É–≥–æ–ª—å–Ω–∏–∫–æ–º
        perimeter = cv2.arcLength(contour, True)
        if perimeter == 0:
            continue

        approx = cv2.approxPolyDP(contour, 0.03 * perimeter, True)
        vertices = len(approx)

        # STOP ‚Äì –æ–±—ã—á–Ω–æ 8-—É–≥–æ–ª—å–Ω–∏–∫, –Ω–æ –¥–∞—ë–º –¥–æ–ø—É—Å–∫
        if 6 <= vertices <= 10:
            x, y, w_box, h_box = cv2.boundingRect(contour)
            aspect_ratio = w_box / float(h_box)
            if 0.7 < aspect_ratio < 1.3:  # –ø–æ—á—Ç–∏ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã–π
                if debug:
                    cv2.drawContours(frame, [approx], -1, (0, 255, 0), 2)
                    cv2.putText(frame, "STOP?", (x, y - 10),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                    cv2.imshow("stop_debug", frame)
                    cv2.waitKey(1)
                return True

    return False

import cv2
import numpy as np
from collections import deque

def detect_line_direction(opt_frame, debug=False):
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–≤–∏–∂–µ–Ω–∏—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —á–µ—Ä–Ω–æ–π –ª–∏–Ω–∏–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
        direction: "left", "right" –∏–ª–∏ "none"
        offset_norm: [-1..1], –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–µ ‚Äì –ª–∏–Ω–∏—è —Å–ª–µ–≤–∞, –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ ‚Äì —Å–ø—Ä–∞–≤–∞
    """
    h, w, _ = opt_frame.shape

    # --- 1. ROI: –Ω–∏–∂–Ω—è—è —á–∞—Å—Ç—å –∫–∞–¥—Ä–∞ ---
    roi_y_start = int(h * 0.6)  # –Ω–∏–∂–Ω–∏–µ 40% –∫–∞–¥—Ä–∞
    roi = opt_frame[roi_y_start:, :]
    roi_h, roi_w = roi.shape[:2]

    # --- 2. Grayscale + CLAHE + blur ---
    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)

    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    gray = clahe.apply(gray)

    gray = cv2.GaussianBlur(gray, (5, 5), 0)

    # --- 3. –ë–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è: —á—ë—Ä–Ω–∞—è –ª–∏–Ω–∏—è -> –±–µ–ª–æ–µ ---
    _, binary = cv2.threshold(
        gray, 0, 255,
        cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU
    )

    # --- 4. –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—è ---
    kernel = np.ones((5, 5), np.uint8)
    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)
    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)

    # --- 5. –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–≤—è–∑–Ω–æ—Å—Ç–∏ ---
    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(
        binary, connectivity=8
    )

    if num_labels <= 1:
        # —Ç–æ–ª—å–∫–æ —Ñ–æ–Ω
        return "none", 0.0

    # stats[0] ‚Äî —Ñ–æ–Ω, –æ—Å—Ç–∞–ª—å–Ω—ã–µ ‚Äî –æ–±—ä–µ–∫—Ç—ã
    areas = stats[1:, cv2.CC_STAT_AREA]
    max_idx = np.argmax(areas)
    largest_label = max_idx + 1
    largest_area = areas[max_idx]

    roi_area = roi_h * roi_w
    min_area = roi_area * 0.025  # –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–µ –æ–±–ª–∞—Å—Ç–∏ (<1.5% ROI)
    if largest_area < min_area:
        return "none", 0.0

    # –ì–µ–æ–º–µ—Ç—Ä–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
    x_obj = stats[largest_label, cv2.CC_STAT_LEFT]
    y_obj = stats[largest_label, cv2.CC_STAT_TOP]
    w_obj = stats[largest_label, cv2.CC_STAT_WIDTH]
    h_obj = stats[largest_label, cv2.CC_STAT_HEIGHT]

    # –¢—Ä–µ–±—É–µ–º, —á—Ç–æ–±—ã –ª–∏–Ω–∏—è –±—ã–ª–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤—ã—Å–æ–∫–æ–π (–≤—ã—Ç—è–Ω—É—Ç–∞—è)
    if h_obj < roi_h * 0.15:  # –º–µ–Ω—å—à–µ 20% –≤—ã—Å–æ—Ç—ã ROI ‚Äî —Å—á–∏—Ç–∞–µ–º —à—É–º–æ–º
        return "none", 0.0

    # –ú–∞—Å–∫–∞ —Ç–æ–ª—å–∫–æ –∫—Ä—É–ø–Ω–µ–π—à–µ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞
    line_mask = (labels == largest_label).astype(np.uint8)

    # --- 6. –ü—Ä–æ–≤–µ—Ä–∫–∞: –ª–∏–Ω–∏—è –¥–æ–ª–∂–Ω–∞ –¥–æ—Ö–æ–¥–∏—Ç—å –¥–æ –Ω–∏–∂–Ω–µ–π —á–∞—Å—Ç–∏ ROI ---
    bottom_band_start = int(roi_h * 0.8)  # –Ω–∏–∂–Ω–∏–µ 20% ROI
    bottom_band = line_mask[bottom_band_start:, :]
    bottom_pixels = np.count_nonzero(bottom_band)

    # –¢—Ä–µ–±—É–µ–º, —á—Ç–æ–±—ã –≤–Ω–∏–∑—É –±—ã–ª–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∏–∫—Å–µ–ª–µ–π –ª–∏–Ω–∏–∏
    min_bottom_pixels = int(roi_w * 0.02)  # —Ö–æ—Ç—è –±—ã 2% —à–∏—Ä–∏–Ω—ã –≤ –ø–∏–∫—Å–µ–ª—è—Ö
    if bottom_pixels < min_bottom_pixels:
        # –ª–∏–Ω–∏—è –≥–¥–µ-—Ç–æ –≤—ã—à–µ, –≤–Ω–∏–∑—É –µ—ë –Ω–µ—Ç -> —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ –¥–ª—è –¥–≤–∏–∂–µ–Ω–∏—è –Ω–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ
        return "none", 0.0

    # --- 7. –¶–µ–Ω—Ç—Ä –ª–∏–Ω–∏–∏ –ø–æ –Ω–∏–∂–Ω–µ–π –ø–æ–ª–æ—Å–µ ---
    ys_bottom, xs_bottom = np.where(bottom_band > 0)
    if len(xs_bottom) == 0:
        return "none", 0.0

    cx_bottom = int(np.mean(xs_bottom))  # X-—Å—Ä–µ–¥–Ω–µ–µ –ø–æ –Ω–∏–∂–Ω–µ–π —á–∞—Å—Ç–∏ –ª–∏–Ω–∏–∏

    # –ø–µ—Ä–µ–≤–æ–¥–∏–º –≤ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤—Å–µ–≥–æ –∫–∞–¥—Ä–∞
    line_center_x = cx_bottom
    frame_center_x = w // 2

    offset_px = line_center_x - frame_center_x
    offset_norm = offset_px / frame_center_x  # –ø—Ä–∏–º–µ—Ä–Ω–æ [-1..1]

    # --- 8. –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å –±–æ–ª–µ–µ —à–∏—Ä–æ–∫–æ–π –º—ë—Ä—Ç–≤–æ–π –∑–æ–Ω–æ–π ---
    threshold = 0.05 # 8% —à–∏—Ä–∏–Ω—ã –∫–∞–¥—Ä–∞, —á—Ç–æ–±—ã —á–∞—â–µ –¥–∞–≤–∞—Ç—å 'none' –æ–∫–æ–ª–æ —Ü–µ–Ω—Ç—Ä–∞

    if offset_norm < -threshold:
        direction = "left"
    elif offset_norm > threshold:
        direction = "right"
    else:
        direction = "none"

    # --- 9. –û—Ç–ª–∞–¥–∫–∞ ---
    if debug:
        debug_frame = opt_frame.copy()

        # –¶–µ–Ω—Ç—Ä –∫–∞–¥—Ä–∞
        cv2.line(debug_frame, (frame_center_x, 0), (frame_center_x, h), (255, 0, 0), 2)

        # –¶–µ–Ω—Ç—Ä –ª–∏–Ω–∏–∏ –≤–Ω–∏–∑—É ROI
        cy_full = roi_y_start + bottom_band_start + (bottom_band.shape[0] // 2)
        cv2.circle(debug_frame, (line_center_x, cy_full), 6, (0, 0, 255), -1)

        text = f"{direction}, off={offset_norm:.2f}"
        cv2.putText(
            debug_frame,
            text,
            (10, 30),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.8,
            (0, 255, 0),
            2
        )

        vis_mask = cv2.cvtColor(binary, cv2.COLOR_GRAY2BGR)
        cv2.imshow("line_binary", vis_mask)
        cv2.imshow("line_debug", debug_frame)
        cv2.waitKey(1)

    return direction, float(offset_norm)



def process_dual_videos(main_video_path, opt_video_path, output_file="generated_check.txt",
                        smooth_window=5):
    main_cap = cv2.VideoCapture(main_video_path)
    opt_cap = cv2.VideoCapture(opt_video_path)
    
    total_frames = int(main_cap.get(cv2.CAP_PROP_FRAME_COUNT))
    frame_count = 0
    stop_detected_frame = 0
    stop_found = False

    markup_data = []

    navigation_stats = {
        "left": 0,
        "right": 0, 
        "none": 0,
        "total_processed": 0
    }

    # –æ—á–µ—Ä–µ–¥—å –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è —Å–º–µ—â–µ–Ω–∏—è
    offset_history = deque(maxlen=smooth_window)

    # === –ù–æ–≤–æ–µ: —Å—á—ë—Ç—á–∏–∫ –ø–æ–¥—Ä—è–¥ –∏–¥—É—â–∏—Ö –∫–∞–¥—Ä–æ–≤ —Å–æ –∑–Ω–∞–∫–æ–º STOP ===
    stop_streak = 0
    stop_threshold_frames = 5  # —Å–∫–æ–ª—å–∫–æ –ø–æ–¥—Ä—è–¥ –∫–∞–¥—Ä–æ–≤ –Ω—É–∂–Ω–æ, —á—Ç–æ–±—ã —Å—á–∏—Ç–∞—Ç—å –∑–Ω–∞–∫ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –Ω–∞–π–¥–µ–Ω–Ω—ã–º

    print(f"–í—Å–µ–≥–æ –∫–∞–¥—Ä–æ–≤ –≤ –≤–∏–¥–µ–æ: {total_frames}")
    print("–ó–∞–ø—É—Å–∫ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–≤—É—Ö –∫–∞–º–µ—Ä...")
    print("–ù–∞–∂–º–∏—Ç–µ 'q' –¥–ª—è –≤—ã—Ö–æ–¥–∞")
    
    while True:
        ret_main, main_frame = main_cap.read()
        ret_opt, opt_frame = opt_cap.read()
        
        if not ret_main or not ret_opt:
            break
        
        frame_count += 1
        
        # ---- 1. –°—Ç–æ–ø-–∑–Ω–∞–∫ –Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–π –∫–∞–º–µ—Ä–µ ----
        is_stop_raw = False
        if frame_count / total_frames > 0.6:  # –ø–æ—Å–ª–µ 80% –Ω–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫
            is_stop_raw = detect_stop_sign_simple(main_frame)

        # –Ω–∞–∫–∞–ø–ª–∏–≤–∞–µ–º –ø–æ–¥—Ä—è–¥ –∏–¥—É—â–∏–µ –∫–∞–¥—Ä—ã —Å –¥–µ—Ç–µ–∫—Ç–æ–º
        if is_stop_raw:
            stop_streak += 1
        else:
            stop_streak = 0

        # —Å—á–∏—Ç–∞–µ–º –∑–Ω–∞–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã–º, –µ—Å–ª–∏ –ø–æ–¥—Ä—è–¥ >= N –∫–∞–¥—Ä–æ–≤ –≤–∏–¥–∏–º STOP
        is_stop = stop_streak >= stop_threshold_frames

        # –æ–¥–∏–Ω —Ä–∞–∑ —Ñ–∏–∫—Å–∏—Ä—É–µ–º –∫–∞–¥—Ä –ø–µ—Ä–≤–æ–≥–æ —É–≤–µ—Ä–µ–Ω–Ω–æ–≥–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è
        if is_stop and not stop_found:
            stop_found = True
            stop_detected_frame = frame_count
        
        # ---- 2. –õ–∏–Ω–∏—è –Ω–∞ –æ–ø—Ç–∏—á–µ—Å–∫–æ–π –∫–∞–º–µ—Ä–µ ----
        direction_raw, offset_norm_raw = detect_line_direction(opt_frame)
        offset_history.append(offset_norm_raw)

        # —Å–≥–ª–∞–∂–µ–Ω–Ω–æ–µ —Å–º–µ—â–µ–Ω–∏–µ
        if len(offset_history) > 0:
            offset_norm_smooth = float(sum(offset_history) / len(offset_history))
        else:
            offset_norm_smooth = offset_norm_raw

        # –ø–µ—Ä–µ—Å—á—ë—Ç –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–æ —Å–≥–ª–∞–∂–µ–Ω–Ω–æ–º—É
        threshold = 0.055
        if offset_norm_smooth < -threshold:
            direction = "left"
        elif offset_norm_smooth > threshold:
            direction = "right"
        else:
            direction = "none"

        navigation_stats[direction] += 1
        navigation_stats["total_processed"] += 1
        
        # ---- 3. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–∞–∑–º–µ—Ç–∫—É ----
        # —Ñ–æ—Ä–º–∞—Ç: –∫–∞–¥—Ä, –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ, –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —Å–º–µ—â–µ–Ω–∏–µ (—Å–≥–ª–∞–∂–µ–Ω–Ω–æ–µ)
        markup_data.append(f"{frame_count} {direction} {offset_norm_smooth:.4f}")
        
        # ---- 4. –û—Ç—Ä–∏—Å–æ–≤–∫–∞ ----
        main_display = main_frame.copy()
        opt_display = opt_frame.copy()
        
        cv2.putText(main_display, f"Main Cam - Frame: {frame_count}/{total_frames}", (10, 30), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
        
        if is_stop:
            cv2.putText(main_display, "STOP SIGN DETECTED!", (10, 60), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
        else:
            status = "Searching..." if frame_count / total_frames > 0.8 else "Waiting 80%..."
            cv2.putText(main_display, f"Stop Sign: {status}", (10, 60), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)
        
        cv2.putText(opt_display, f"Optical Cam - Dir: {direction}", (10, 30), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
        cv2.putText(opt_display, f"Offset: {offset_norm_smooth:.2f}", (10, 55), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)
        cv2.putText(opt_display, f"Progress: {frame_count/total_frames*100:.1f}%", (10, 80), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)
        
        if main_display.shape != opt_display.shape:
            opt_display = cv2.resize(opt_display, (main_display.shape[1], main_display.shape[0]))
        
        combined = np.vstack([main_display, opt_display])
        cv2.imshow('Dual Camera Processing', combined)
        
        # –≤—ã—Ö–æ–¥–∏–º –ª–∏–±–æ –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ –Ω–∞–π–¥–µ–Ω–Ω–æ–º—É STOP, –ª–∏–±–æ –ø–æ 'q'
        if stop_found or cv2.waitKey(1) & 0xFF == ord('q'):
            break
    
    main_cap.release()
    opt_cap.release()
    cv2.destroyAllWindows()
    
    save_markup_to_file(markup_data, output_file, stop_found, stop_detected_frame)
    
    return stop_found, stop_detected_frame, frame_count, total_frames, navigation_stats, markup_data


def save_markup_to_file(markup_data, filename, stop_found, stop_frame):
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–∞–∑–º–µ—Ç–∫—É –≤ —Ñ–∞–π–ª –≤ —Ç–æ–º –∂–µ —Ñ–æ—Ä–º–∞—Ç–µ, —á—Ç–æ –∏ check.txt
    """
    with open(filename, 'w') as f:
        for line in markup_data:
            f.write(line + '\n')
    
    print(f"\n‚úÖ –†–∞–∑–º–µ—Ç–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ —Ñ–∞–π–ª: {filename}")
    print(f"üìù –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(markup_data)}")
    if stop_found:
        print(f"üõë –ó–Ω–∞–∫ —Å—Ç–æ–ø –æ–±–Ω–∞—Ä—É–∂–µ–Ω –Ω–∞ –∫–∞–¥—Ä–µ: {stop_frame}")

def video_process(main_img, opt_img):
    """
    –ê–Ω–∞–ª–æ–≥ —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ eval.py
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
        direction: "left"/"right"/"none"
        is_stop: True/False
    """
    direction, _ = detect_line_direction(opt_img)
    is_stop = detect_stop_sign_simple(main_img)
    return direction, is_stop


# –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–¥
if __name__ == "__main__":
    main_video_path = "video/main--effiroom.ru.mp4"
    opt_video_path = "video/opt--effiroom.ru.mp4"
    output_markup_file = "generated_check.txt"
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ–±–∞ –≤–∏–¥–µ–æ
    stop_found, stop_frame, processed_frames, total_frames, nav_stats, markup_data = process_dual_videos(
        main_video_path, opt_video_path, output_markup_file
    )
    
    if stop_found:
        frames_remaining = total_frames - stop_frame
        progress_percent = (stop_frame / total_frames) * 100

        print(f" –ö–∞–¥—Ä –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è: {stop_frame}")
        print(f" –ü—Ä–æ–π–¥–µ–Ω–æ –∫–∞–¥—Ä–æ–≤: {stop_frame}/{total_frames} ({progress_percent:.1f}%)")
    else:
        print(f" –ó–Ω–∞–∫ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω")
        print(f" –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∫–∞–¥—Ä–æ–≤: {processed_frames}/{total_frames}")