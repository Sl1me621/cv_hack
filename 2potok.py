import cv2
import numpy as np

def detect_stop_sign_simple(frame):
    """
    –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∑–Ω–∞–∫–∞
    """
    # –ü–æ—Ä–æ–≥–∏ –∫—Ä–∞—Å–Ω–æ–≥–æ —Ü–≤–µ—Ç–∞
    lower_red1 = np.array([0, 127, 203])
    upper_red1 = np.array([12, 255, 238])
    lower_red2 = np.array([170, 127, 203])
    upper_red2 = np.array([179, 255, 238])
    
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
    
    # –ú–∞—Å–∫–∞ –∫—Ä–∞—Å–Ω–æ–≥–æ
    mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
    mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
    red_mask = cv2.bitwise_or(mask1, mask2)
    
    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è
    kernel = np.ones((5,5), np.uint8)
    red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_OPEN, kernel)
    
    # –ü–æ–∏—Å–∫ –∫–æ–Ω—Ç—É—Ä–æ–≤
    contours, _ = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    for contour in contours:
        area = cv2.contourArea(contour)
        if 500 < area < 500000:
            perimeter = cv2.arcLength(contour, True)
            if perimeter > 0:
                circularity = 4 * np.pi * area / (perimeter * perimeter)
                if circularity > 0.7:
                    return True
    return False

import cv2
import numpy as np

def detect_line_direction(opt_frame, debug=False):
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–≤–∏–∂–µ–Ω–∏—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —á–µ—Ä–Ω–æ–π –ª–∏–Ω–∏–∏ –Ω–∞ –æ–ø—Ç–∏—á–µ—Å–∫–æ–π –∫–∞–º–µ—Ä–µ.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
        direction: "left", "right" –∏–ª–∏ "none"
        offset_norm: –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —Å–º–µ—â–µ–Ω–∏–µ [-1..1] (–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–µ ‚Äì –ª–∏–Ω–∏—è —Å–ª–µ–≤–∞, –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ ‚Äì —Å–ø—Ä–∞–≤–∞)
    """

    # --- 1. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ ---
    # –†–∞–±–æ—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ —Å –Ω–∏–∂–Ω–µ–π —á–∞—Å—Ç—å—é –∫–∞–¥—Ä–∞ (—Ç–∞–º –æ–±—ã—á–Ω–æ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ª–∏–Ω–∏—è)
    h, w, _ = opt_frame.shape
    roi_y_start = int(h * 0.6)  # –±–µ—Ä–µ–º –Ω–∏–∂–Ω–∏–µ 40% –∫–∞–¥—Ä–∞
    roi = opt_frame[roi_y_start:, :]

    # –í –≥—Ä–∞–¥–∞—Ü–∏–∏ —Å–µ—Ä–æ–≥–æ + —Ä–∞–∑–º—ã—Ç–∏–µ –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è —à—É–º–∞
    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
    gray = cv2.GaussianBlur(gray, (5, 5), 0)

    # --- 2. –ë–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è ---
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º Otsu, —á—Ç–æ–±—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–¥–±–∏—Ä–∞—Ç—å –ø–æ—Ä–æ–≥ –ø–æ–¥ –æ—Å–≤–µ—â–µ–Ω–∏–µ
    _, binary = cv2.threshold(
        gray, 0, 255,
        cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU
    )

    # --- 3. –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—è (—á–∏—Å—Ç–∏–º –º–∞—Å–∫—É) ---
    kernel = np.ones((5, 5), np.uint8)
    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)
    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)

    # --- 4. –ü–æ–∏—Å–∫ –∫–æ–Ω—Ç—É—Ä–æ–≤ ---
    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if not contours:
        return "none", 0.0

    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –ø–ª–æ—â–∞–¥–∏, —á—Ç–æ–±—ã —É–±—Ä–∞—Ç—å –º–µ–ª–∫–∏–π –º—É—Å–æ—Ä
    roi_area = binary.shape[0] * binary.shape[1]
    min_area = roi_area * 0.01  # –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –∫–æ–Ω—Ç—É—Ä—ã –º–µ–Ω—å—à–µ 1% –æ—Ç –ø–ª–æ—â–∞–¥–∏ ROI
    candidates = [c for c in contours if cv2.contourArea(c) > min_area]

    if not candidates:
        return "none", 0.0

    # --- 5. –í—ã–±–æ—Ä "–ø–æ—Ö–æ–∂–µ–≥–æ –Ω–∞ –ª–∏–Ω–∏—é" –∫–æ–Ω—Ç—É—Ä–∞ ---
    def line_score(cnt):
        x, y, cw, ch = cv2.boundingRect(cnt)
        area = cw * ch + 1e-6
        aspect = max(cw, ch) / (min(cw, ch) + 1e-6)  # –≤—ã—Ç—è–Ω—É—Ç–æ—Å—Ç—å
        fill = cv2.contourArea(cnt) / area          # –Ω–∞—Å–∫–æ–ª—å–∫–æ –∫–æ–Ω—Ç—É—Ä –∑–∞–ø–æ–ª–Ω—è–µ—Ç –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫
        # —á–µ–º –≤—ã—Ç—è–Ω—É—Ç–µ–µ –∏ –ø–ª–æ—Ç–Ω–µ–µ –∫–æ–Ω—Ç—É—Ä ‚Äì —Ç–µ–º –≤—ã—à–µ score
        return aspect * fill

    largest_contour = max(candidates, key=line_score)

    # --- 6. –¢–æ—á–Ω—ã–π —Ü–µ–Ω—Ç—Ä –ø–æ –º–æ–º–µ–Ω—Ç–∞–º ---
    M = cv2.moments(largest_contour)
    if M["m00"] == 0:
        return "none", 0.0

    cx = int(M["m10"] / M["m00"])  # x-–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞ —Ü–µ–Ω—Ç—Ä–∞ –≤ ROI
    line_center_x = cx  # —É–∂–µ –≤ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞—Ö ROI (–ø–æ x —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –∫–∞–¥—Ä–æ–º)

    # –¶–µ–Ω—Ç—Ä –∫–∞–¥—Ä–∞ –ø–æ x
    frame_center_x = w // 2

    # --- 7. –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —Å–º–µ—â–µ–Ω–∏–µ –∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ ---
    offset_px = line_center_x - frame_center_x
    offset_norm = offset_px / frame_center_x  # –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ –ø—Ä–∏–º–µ—Ä–Ω–æ [-1..1]

    # –ü–æ—Ä–æ–≥ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ ‚Äì 5% —à–∏—Ä–∏–Ω—ã –∫–∞–¥—Ä–∞
    threshold = 0.05

    if offset_norm < -threshold:
        direction = "left"
    elif offset_norm > threshold:
        direction = "right"
    else:
        direction = "none"

    # --- 8. –û—Ç–ª–∞–¥–æ—á–Ω—ã–π –≤—ã–≤–æ–¥ (–ø–æ –∂–µ–ª–∞–Ω–∏—é) ---
    if debug:
        debug_frame = opt_frame.copy()
        # —Ä–∏—Å—É–µ–º –ª–∏–Ω–∏—é –∏ —Ü–µ–Ω—Ç—Ä
        cv2.line(debug_frame, (frame_center_x, 0), (frame_center_x, h), (255, 0, 0), 2)
        cv2.circle(debug_frame, (line_center_x, roi_y_start + binary.shape[0] // 2), 5, (0, 0, 255), -1)
        cv2.putText(
            debug_frame,
            f"{direction}, offset={offset_norm:.2f}",
            (10, 30),
            cv2.FONT_HERSHEY_SIMPLEX,
            1,
            (0, 255, 0),
            2
        )
        # –º–æ–∂–Ω–æ –ø–æ–∫–∞–∑–∞—Ç—å –æ–∫–Ω–æ, –µ—Å–ª–∏ –∑–∞–ø—É—Å–∫–∞–µ—à—å –Ω–µ –Ω–∞ –¥—Ä–æ–Ω–µ:
        # cv2.imshow("debug", debug_frame)
        # cv2.imshow("binary", binary)
        # cv2.waitKey(1)

    return direction


def process_dual_videos(main_video_path, opt_video_path, output_file="generated_check.txt"):
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–≤–∞ –≤–∏–¥–µ–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    """
    main_cap = cv2.VideoCapture(main_video_path)
    opt_cap = cv2.VideoCapture(opt_video_path)
    
    # –ü–æ–ª—É—á–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤ –≤ –≤–∏–¥–µ–æ
    total_frames = int(main_cap.get(cv2.CAP_PROP_FRAME_COUNT))
    frame_count = 0
    stop_detected_frame = 0
    stop_found = False
    
    # –°–ø–∏—Å–æ–∫ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ç–∫–∏
    markup_data = []
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è –Ω–∞–≤–∏–≥–∞—Ü–∏–∏
    navigation_stats = {
        "left": 0,
        "right": 0, 
        "none": 0,
        "total_processed": 0
    }
    
    print(f"–í—Å–µ–≥–æ –∫–∞–¥—Ä–æ–≤ –≤ –≤–∏–¥–µ–æ: {total_frames}")
    print("–ó–∞–ø—É—Å–∫ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–≤—É—Ö –∫–∞–º–µ—Ä...")
    print("–ù–∞–∂–º–∏—Ç–µ 'q' –¥–ª—è –≤—ã—Ö–æ–¥–∞")
    
    while True:
        ret_main, main_frame = main_cap.read()
        ret_opt, opt_frame = opt_cap.read()
        
        if not ret_main or not ret_opt:
            break
        
        frame_count += 1
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Å–Ω–æ–≤–Ω–æ–π –∫–∞–º–µ—Ä—ã - –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∑–Ω–∞–∫–∞
        is_stop = False
        if frame_count / total_frames > 0.9:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–Ω–∞–∫ —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ 80% –∫–∞–¥—Ä–æ–≤
            is_stop = detect_stop_sign_simple(main_frame)
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–ø—Ç–∏—á–µ—Å–∫–æ–π –∫–∞–º–µ—Ä—ã - –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
        direction = detect_line_direction(opt_frame)
        navigation_stats[direction] += 1
        navigation_stats["total_processed"] += 1
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ —Ä–∞–∑–º–µ—Ç–∫—É
        markup_data.append(f"{frame_count} {direction}")
        
        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –Ω–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–º –∫–∞–¥—Ä–µ
        main_display = main_frame.copy()
        opt_display = opt_frame.copy()
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–π –∫–∞–º–µ—Ä–µ
        cv2.putText(main_display, f"Main Cam - Frame: {frame_count}/{total_frames}", (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
        
        if is_stop:
            stop_found = True
            stop_detected_frame = frame_count
            cv2.putText(main_display, "STOP SIGN DETECTED!", (10, 60), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
        else:
            status = "Searching..." if frame_count / total_frames > 0.8 else "Waiting 80%..."
            cv2.putText(main_display, f"Stop Sign: {status}", (10, 60), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–∞ –æ–ø—Ç–∏—á–µ—Å–∫–æ–π –∫–∞–º–µ—Ä–µ
        cv2.putText(opt_display, f"Optical Cam - Direction: {direction}", (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
        cv2.putText(opt_display, f"Progress: {frame_count/total_frames*100:.1f}%", (10, 60), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∫–∞–¥—Ä—ã –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        if main_display.shape != opt_display.shape:
            # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–º—É —Ä–∞–∑–º–µ—Ä—É –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            opt_display = cv2.resize(opt_display, (main_display.shape[1], main_display.shape[0]))
        
        combined = np.vstack([main_display, opt_display])
        cv2.imshow('Dual Camera Processing', combined)
        
        # –í—ã—Ö–æ–¥ –ø—Ä–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–∏ –∑–Ω–∞–∫–∞ –∏–ª–∏ –Ω–∞–∂–∞—Ç–∏–∏ 'q'
        if stop_found or cv2.waitKey(1) & 0xFF == ord('q'):
            break
    
    main_cap.release()
    opt_cap.release()
    cv2.destroyAllWindows()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–∞–∑–º–µ—Ç–∫—É –≤ —Ñ–∞–π–ª
    save_markup_to_file(markup_data, output_file, stop_found, stop_detected_frame)
    
    return stop_found, stop_detected_frame, frame_count, total_frames, navigation_stats, markup_data

def save_markup_to_file(markup_data, filename, stop_found, stop_frame):
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–∞–∑–º–µ—Ç–∫—É –≤ —Ñ–∞–π–ª –≤ —Ç–æ–º –∂–µ —Ñ–æ—Ä–º–∞—Ç–µ, —á—Ç–æ –∏ check.txt
    """
    with open(filename, 'w') as f:
        for line in markup_data:
            f.write(line + '\n')
    
    print(f"\n‚úÖ –†–∞–∑–º–µ—Ç–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ —Ñ–∞–π–ª: {filename}")
    print(f"üìù –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(markup_data)}")
    if stop_found:
        print(f"üõë –ó–Ω–∞–∫ —Å—Ç–æ–ø –æ–±–Ω–∞—Ä—É–∂–µ–Ω –Ω–∞ –∫–∞–¥—Ä–µ: {stop_frame}")

def video_process(main_img, opt_img):
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–¥—Ä–æ–≤ (–∞–Ω–∞–ª–æ–≥ —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ eval.py)
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∏ —Ñ–ª–∞–≥ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∑–Ω–∞–∫–∞
    """
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ –æ–ø—Ç–∏—á–µ—Å–∫–æ–π –∫–∞–º–µ—Ä–µ
    direction = detect_line_direction(opt_img)
    
    # –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∑–Ω–∞–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–π –∫–∞–º–µ—Ä–µ
    is_stop = detect_stop_sign_simple(main_img)
    
    return direction, is_stop

# –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–¥
if __name__ == "__main__":
    main_video_path = "video/main--effiroom.ru.mp4"
    opt_video_path = "video/opt--effiroom.ru.mp4"
    output_markup_file = "generated_check.txt"
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ–±–∞ –≤–∏–¥–µ–æ
    stop_found, stop_frame, processed_frames, total_frames, nav_stats, markup_data = process_dual_videos(
        main_video_path, opt_video_path, output_markup_file
    )
    
    if stop_found:
        frames_remaining = total_frames - stop_frame
        progress_percent = (stop_frame / total_frames) * 100

        print(f" –ö–∞–¥—Ä –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è: {stop_frame}")
        print(f" –ü—Ä–æ–π–¥–µ–Ω–æ –∫–∞–¥—Ä–æ–≤: {stop_frame}/{total_frames} ({progress_percent:.1f}%)")
    else:
        print(f" –ó–Ω–∞–∫ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω")
        print(f" –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∫–∞–¥—Ä–æ–≤: {processed_frames}/{total_frames}")